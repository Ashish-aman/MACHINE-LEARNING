# -*- coding: utf-8 -*-
"""M22MA002_task2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kDeH4MaNrhksEJaVVOLjaK5u4xnkAayV
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# File Id for cardetails datasset uploaded and saved on google drive
file_id = '1sU7bUUjH9RwbU14XaadAhLe_Ao474Irf'
datafile = pd.read_csv(f'https://drive.google.com/uc?export=download&id={file_id}',
                 names=['symboling','normalized-losses','make','fuel-type','aspiration','num-of-doors','body-style','drive-wheels','engine-location','wheel-base','length','width','height','curb-weight','engine-type','num-of-cylinders','engine-size','fuel-system','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price'])
datafile.head()

nol = datafile['normalized-losses'].to_numpy()


nol = np.where(nol=='?',0,nol)
nol_int = np.array(nol,dtype='int')
nol_median = np.median(nol_int)
nol = np.where(nol==0,nol_median,nol)

datafile['normalized-losses'] = np.array(nl,dtype=int)

# print(df)
# map string to int such that can be used in linear regression
data_map = dict()
# creating map as
# mp = {
#         'a':[0,1,2],
#         'b':[0,1],
# }
for j in datafile:
        
        data_map[j] = {}
        k = 0
        for i in set(datafile[j]):
                data_map[j][i] = k
                k+=1

# print(data_map)
for i in datafile:
        col = datafile[i].to_numpy()
        if col.dtype == object:
                # print(col)
                for j in range(len(col)):
                        # print(data_map[i])
                        col[j] = data_map[i][col[j]]
                        # print(col[j])

datafile

train_df = datafile.sample(frac = 0.8)
test_df = datafile.drop(train_df.index)

# Dependent variables
X_training = train_df[['fuel-type','aspiration','num-of-doors','body-style','drive-wheels','engine-location','wheel-base','length','width','height','curb-weight','engine-type','num-of-cylinders','engine-size','fuel-system','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg']]
# Independent variables
y_training = train_df['price']

X_test = test_df[['fuel-type','aspiration','num-of-doors','body-style','drive-wheels','engine-location','wheel-base','length','width','height','curb-weight','engine-type','num-of-cylinders','engine-size','fuel-system','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg']]
y_test = test_df['price']

X_training,y_training
m = len(y_training) # Number of training examples
X_training.shape,y_training.shape,X_test.shape,y_test.shape

# Lets use hstack() function from numpy to add column of ones to X feature 
# This will be our final X matrix (feature matrix)
X_train = np.hstack((np.ones((m,1)), X_training))
print(X_train[-5:])
# X_train.shape,y_train.shape

def compute_cost(X, y, theta):
    predictions = X.dot(theta)
    errors = np.subtract(predictions, y) 
    sqrErrors = np.square(errors)
    J = 1/(2 * m) * errors.T.dot(errors)
    return J

def gradient_descent(X, y, theta, alpha, iterations):
    cost_history = np.zeros(iterations)
    # print(X.shape())
    for i in range(iterations):
        predictions = X.dot(theta)
        #print('predictions= ', predictions[:5])
        errors = np.subtract(predictions, y)
        #print('errors= ', errors[:5])
        sum_delta = (alpha / m) * X.transpose().dot(errors);
        #print('sum_delta= ', sum_delta[:5])
        theta = theta - sum_delta;

        cost_history[i] = compute_cost(X, y, theta)    

    return theta, cost_history

thetax = np.zeros(23)
iterations = 25;
alpha = 0.05;

print(X_train.shape)
thetax, cost_history = gradient_descent(X_train, y_training, thetax, alpha, iterations)
print('Final value of theta =\n', thetax)
print('First 5 values from cost_history =', cost_history[:5])
print('Last 5 values from cost_history =', cost_history[-5 :])

y_pred = X_test.dot(thetax[1:])
y_pred += thetax[0]
# sum((y_test-y_pred)**2)/(2*m)
# sum((y_pred-np.mean(y_train))**2)/sum((y_train-np.mean(y_train))**2)
sum((y_pred-np.mean(train_df['price']))**2)/sum((train_df['price']-np.mean(train_df['price']))**2)

"""## Trying with sklearn library

"""

from sklearn.linear_model import LinearRegression
reg = LinearRegression()
X_train = train_df[['fuel-type','aspiration','num-of-doors','body-style','drive-wheels','engine-location','wheel-base','length','width','height','curb-weight','engine-type','num-of-cylinders','engine-size','fuel-system','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg']]
y_train = train_df['price']
 
# y = np.reshape(Y,(-1,1))

reg.fit(X_train,y_train)

reg.coef_,reg.intercept_
print(X.shape,Y.shape)

y_pred_sk = reg.predict(X_test)
# sum((y_test-y_pred_sk)**2)/(2*m)
sum((y_pred_sk-np.mean(train_df['price']))**2)/sum((train_df['price']-np.mean(train_df['price']))**2)

